# This is a template config file that is first used to create a toy dataset by running
# python toy_data_generator.py -c ../experiments/toys.yml
# in `utils` directory, with an optional flag `-v` for visual to see data being generated
# The following input variables can be edited safely@
# project_name, project_directory, c_date, common:IMAGE_W (must be the same as IMAGE_H), number_of_images for train and test dataset
project_name: 'toys'
project_directory: '../data/toys' #adding a '..' because the programs are run from subdirectories. feel free to specify an absolute path if that offends you
c_date: '2023Jun29' #this is basically a part of project name if you wish.

#The general project settings, will be the same if you keep the directory structure intact
weights_dir: 'weights/'
annotations_dir: 'annotations/'
raw_imgs_dir: 'raw_imgs/'
tracks_dir: 'extracted_tracks/'
bbox_images_dir: 'extracted_tracks/'
groundtruths_dir: 'results/groundtruths/'
predictions_dir: 'results/predictions/'
results_dir: 'results/'
seq_yml: 'seq_data.yml'

#This is annotations
preped_images_dir: "subsets/sequences/"
tracking_setup: 'track_setup_1'

autogen_model:
  pretrained_weights: 'yolo-v3-coco.h5'
  pretrained_weights_md5: "26cf8e8b5ba9d9d4a3778f9747e3407a" #leave empty if you are retraining
  num_class: 1
  obj_thresh: 0.9
  nms_thresh: 0.05
autogen_annotations_fname: 'autogenerated_annotations.yml'
autogen_annotations_md5 : ''

seq_fname: 'alpha.txt'
checked_annotations_fname: 'train_data.yml'
checked_annotations_md5 : ''

results_config_name: 'results_file.yml'

models:
  model_1:
    pretrained_weights: 'yolo-v3-coco.h5'
    pretrained_weights_md5: "26cf8e8b5ba9d9d4a3778f9747e3407a" #leave empty if you are retraining
    training_sets: ['train']
    phases: 2
    num_class: 1
    obj_thresh: 0.9
    nms_thresh: 0.1
    phase_one:
      BATCH_SIZE: 16
      EPOCHS: 50
      LR: 0.5e-3
      B1: 0.9
      B2: 0.999
      EPS: 0.1e-7
      MIN_DELTA: 0.01
      PATIENCE: 5
    phase_two:
      BATCH_SIZE: 4
      EPOCHS: 50
      LR: 0.1e-3
      B1: 0.9
      B2: 0.999
      EPS: 0.1e-7
      MIN_DELTA: 0.01
      PATIENCE: 5

testing_sets: ['test']


subsets:
  train:
    directory: 'subsets/train/'
    number_of_images: 500
    description: 'easy subset to train on'
    filelist: '' #if filelist is empty, use regex
    regex: '*.jpg'
  test:
    directory: 'subsets/test/'
    number_of_images: 100
    description: 'subset to test on and create a video for tracking'
    filelist: ''
    regex: '*.jpg'

track_setup_1:
  videos_name_regex: "videos/*.avi" #for use by transform.py which also preps the following yml file
  videos_fps: 10
  link_iou: 0.1
  step_frames: 1 #how many frames between each step of a tracker/downsampling. Remember to adjust link_iou if jump is bigger
  videos_list: "my_videos.yml" #after transforms.py was run this is where video list live
  groundtruths_dir: 'gt/'
  predictions_dir: 'pred/'
  weights: 'toys_model_1_phase_two_2023Mar11.h5'
  # weights: 'yolo-v3-coco.h5'
  weights_md5: ''
  num_class: 1
  obj_thresh: 0.9
  nms_thresh: 0.1
  max_age: 6 #how
  track_thresh: 0.75 #only return tracks with average confidence above this value
  init_thresh: 0.9
  init_nms: 0.1
  hold_without: 2 #how long to show track alive without detections (at max age it will be killed anyway

common:
  LABELS: ['toy']
  MAX_L: 400
  MIN_L: 4
  OBJECT_SCALE: 5.0
  NO_OBJECT_SCALE: 1.0
  COORD_SCALE: 2.0
  CLASS_SCALE: 1.0
  display: 1
  save_output: 1
  show_detections: 1 # flag to show all detections in image
  corrections_buffer_size: 200 #number of frames kept in the memory for rewinding back the tracks

deepBeastLinking:
  untrained_annotations_fname: ''
  trained_annotations_fname: ''

  #checked annotations are used for training:
  checked_annotations_fname: 'seq_data.yml'
  seq_fname: 'A.txt'
  detection_net_weights: 'toys_model_1_phase_two_2023Mar11.h5'
  linking_net_weights: 'toys_link.h5'

  #training parameters
  FINE_TUNE: 1
  BATCH_SIZE: 16
  EPOCHS: 100
  LR: 0.5e-4

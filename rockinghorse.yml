#set this up to get funny behaviour quickly. Like training for 1 epoch
TEST_RUN: 1
DEBUG: 1

data_dir: 'data/rockinghorse/'
weights_dir: 'weights/'
tracks_dir: "tracks/"
movie_dir: ''

training_type: 'specific' # generic|specific
untrained_annotations_fname: 'annotations.yml'
trained_annotations_fname: 'annotations-trained.yml'
test_videos_name_regex: "videos/*.mp4"

#checked annotations are used for training:
checked_annotations_fname: 'annotations-checked.yml' 
generic:
  train_files_regex: "stills/*.png"
  weights: 'yolo-v3-coco.h5'
  weights_md5: "26cf8e8b5ba9d9d4a3778f9747e3407a" #leave empty if you are retraining
  num_class: 80
  obj_thresh: 0.2
  nms_thresh: 0.3

specific:
  train_files_regex: "DEP*.png"
  weights: 'horses-yolo.h5'
  weights_md5: "eea943779c713c89bab51cd94bf7ae71"
  num_class: 1
  obj_thresh: 0.7
  nms_thresh: 0.5

trained_weights: 'trained-horses-yolo.h5'

# Training parameters:
# phase_one top layers, normal learning rate
# phase_two all layers, small learning rate
FINE_TUNE_PHASE: 'phase_one'
phase_one:
  BATCH_SIZE: 32
  EPOCHS: 500
  LR: 0.5e-4
phase_two:
  BATCH_SIZE: 4
  EPOCHS: 100
  LR: 0.5e-4

LABELS: ['aoi']
IMAGE_H: 864
IMAGE_W: 864
MAX_L: 400
MIN_L: 4

#TRACKING:
tracking_setup: "mk1"

mk1:
  videos_name_regex: "videos/*.mp4" #for use by transform.py which also preps the following yml file
  videos_list: "horse_videos.yml"
  weights: 'horses-yolo.h5'
  weights_md5: "eea943779c713c89bab51cd94bf7ae71"
  obj_thresh: 0.8
  nms_thresh: 0.5
  max_age: 30
  track_thresh: 0.3
  init_thresh: 0.8
  init_nms: 0.0
  link_iou: 0.1
  step_frames: 5 #how many frames between each step of a tracker/downsampling. Remember to adjust link_iou if jump is bigger

NO_OBJECT_SCALE: 1.0
OBJECT_SCALE: 5.0
COORD_SCALE: 2.0
CLASS_SCALE: 1.0

#Running tracker
save_output: 1
showDetections: 1 # flag to show all detections in image
